@inproceedings{DBLP:conf/sosp/KwonLZ0ZY0ZS23,
  author    = {Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph Gonzalez and Hao Zhang and Ion Stoica},
  title     = {Efficient Memory Management for Large Language Model Serving with PagedAttention},
  year      = {2023},
  cdate     = {1672531200000},
  pages     = {611-626},
  url       = {https://doi.org/10.1145/3600006.3613165},
  booktitle = {SOSP},
  crossref  = {conf/sosp/2023}
}

@inproceedings{zheng2024sglang,
  title     = {{SGL}ang: Efficient Execution of Structured Language Model Programs},
  author    = {Lianmin Zheng and Liangsheng Yin and Zhiqiang Xie and Chuyue Sun and Jeff Huang and Cody Hao Yu and Shiyi Cao and Christos Kozyrakis and Ion Stoica and Joseph E. Gonzalez and Clark Barrett and Ying Sheng},
  booktitle = {The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year      = {2024},
  url       = {https://openreview.net/forum?id=VqkAKQibpq}
}

@misc{bai2025qwen25vltechnicalreport,
  title         = {Qwen2.5-VL Technical Report},
  author        = {Shuai Bai and Keqin Chen and Xuejing Liu and Jialin Wang and Wenbin Ge and Sibo Song and Kai Dang and Peng Wang and Shijie Wang and Jun Tang and Humen Zhong and Yuanzhi Zhu and Mingkun Yang and Zhaohai Li and Jianqiang Wan and Pengfei Wang and Wei Ding and Zheren Fu and Yiheng Xu and Jiabo Ye and Xi Zhang and Tianbao Xie and Zesen Cheng and Hang Zhang and Zhibo Yang and Haiyang Xu and Junyang Lin},
  year          = {2025},
  eprint        = {2502.13923},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2502.13923}
}

@misc{wang2024qwen2vlenhancingvisionlanguagemodels,
  title         = {Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author        = {Peng Wang and Shuai Bai and Sinan Tan and Shijie Wang and Zhihao Fan and Jinze Bai and Keqin Chen and Xuejing Liu and Jialin Wang and Wenbin Ge and Yang Fan and Kai Dang and Mengfei Du and Xuancheng Ren and Rui Men and Dayiheng Liu and Chang Zhou and Jingren Zhou and Junyang Lin},
  year          = {2024},
  eprint        = {2409.12191},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2409.12191}
}

@inproceedings{pmlr-v202-radford23a,
  title     = {Robust Speech Recognition via Large-Scale Weak Supervision},
  author    = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and Mcleavey, Christine and Sutskever, Ilya},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  pages     = {28492--28518},
  year      = {2023},
  editor    = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume    = {202},
  series    = {Proceedings of Machine Learning Research},
  month     = {23--29 Jul},
  publisher = {PMLR},
  pdf       = {https://proceedings.mlr.press/v202/radford23a/radford23a.pdf},
  url       = {https://proceedings.mlr.press/v202/radford23a.html},
  abstract  = {We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results without the need for any dataset specific fine-tuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.}
}

@inproceedings{yoo2003slurm,
  title        = {Slurm: Simple linux utility for resource management},
  author       = {Yoo, Andy B and Jette, Morris A and Grondona, Mark},
  booktitle    = {Workshop on job scheduling strategies for parallel processing},
  pages        = {44--60},
  year         = {2003},
  organization = {Springer}
}

@misc{xu2025qwen25omnitechnicalreport,
  title         = {Qwen2.5-Omni Technical Report},
  author        = {Jin Xu and Zhifang Guo and Jinzheng He and Hangrui Hu and Ting He and Shuai Bai and Keqin Chen and Jialin Wang and Yang Fan and Kai Dang and Bin Zhang and Xiong Wang and Yunfei Chu and Junyang Lin},
  year          = {2025},
  eprint        = {2503.20215},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2503.20215}
}

@misc{abdin2024phi4technicalreport,
  title         = {Phi-4 Technical Report},
  author        = {Marah Abdin and Jyoti Aneja and Harkirat Behl and SÃ©bastien Bubeck and Ronen Eldan and Suriya Gunasekar and Michael Harrison and Russell J. Hewett and Mojan Javaheripi and Piero Kauffmann and James R. Lee and Yin Tat Lee and Yuanzhi Li and Weishung Liu and Caio C. T. Mendes and Anh Nguyen and Eric Price and Gustavo de Rosa and Olli Saarikivi and Adil Salim and Shital Shah and Xin Wang and Rachel Ward and Yue Wu and Dingli Yu and Cyril Zhang and Yi Zhang},
  year          = {2024},
  eprint        = {2412.08905},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2412.08905}
}

@inproceedings{gligoric-etal-2025-unconfident,
  title     = {Can Unconfident {LLM} Annotations Be Used for Confident Conclusions?},
  author    = {Gligoric, Kristina  and
               Zrnic, Tijana  and
               Lee, Cinoo  and
               Candes, Emmanuel  and
               Jurafsky, Dan},
  editor    = {Chiruzzo, Luis  and
               Ritter, Alan  and
               Wang, Lu},
  booktitle = {Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  month     = apr,
  year      = {2025},
  address   = {Albuquerque, New Mexico},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.naacl-long.179/},
  doi       = {10.18653/v1/2025.naacl-long.179},
  pages     = {3514--3533},
  isbn      = {979-8-89176-189-6},
  abstract  = {Large language models (LLMs) have shown high agreement with human raters across a variety of tasks, demonstrating potential to ease the challenges of human data collection. In computational social science (CSS), researchers are increasingly leveraging LLM annotations to complement slow and expensive human annotations. Still, guidelines for collecting and using LLM annotations, without compromising the validity of downstream conclusions, remain limited. We introduce Confidence-driven inference: a method that combines LLM annotations and LLM confidence indicators to strategically select which human annotations should be collected, with the goal of producing accurate statistical estimates and provably valid confidence intervals while reducing the number of human annotations needed. Our approach comes with safeguards against LLM annotations of poor quality, guaranteeing that the conclusions will be both valid and no less accurate than if we only relied on human annotations. We demonstrate the effectiveness of Confidence-driven inference over baselines in statistical estimation tasks across three CSS settings{---}text politeness, stance, and bias{---}reducing the needed number of human annotations by over 25{\%} in each. Although we use CSS settings for demonstration, Confidence-driven inference can be used to estimate most standard quantities across a broad range of NLP problems.}
}