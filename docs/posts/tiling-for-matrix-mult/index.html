<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tomas Ruiz">
<meta name="dcterms.date" content="2024-12-23">

<title>How Does Tiling Speed Up Matrix Multiplications on GPUs? – All Posts</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">All Posts</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../subscribe.html"> 
<span class="menu-text">Subscribe</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tomas-ruiz-649907b3/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/tomasruizt"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">How Does Tiling Speed Up Matrix Multiplications on GPUs?</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Mathematics</div>
                <div class="quarto-category">GPUs</div>
              </div>
                  </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-heading">Affiliation</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author">Tomas Ruiz <a href="mailto:t.ruiz@lmu.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
    </div>
    <div class="quarto-title-meta-contents">
          <p class="affiliation">
              Ludwig-Maximilians-Universität München
            </p>
        </div>
    </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 23, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#matrix-multiplication-recap" id="toc-matrix-multiplication-recap" class="nav-link active" data-scroll-target="#matrix-multiplication-recap">Matrix Multiplication Recap</a></li>
  <li><a href="#compute-intensity" id="toc-compute-intensity" class="nav-link" data-scroll-target="#compute-intensity">Compute Intensity</a></li>
  <li><a href="#memory-access-analysis" id="toc-memory-access-analysis" class="nav-link" data-scroll-target="#memory-access-analysis">Memory Access Analysis</a>
  <ul class="collapse">
  <li><a href="#naive-memory-access" id="toc-naive-memory-access" class="nav-link" data-scroll-target="#naive-memory-access">Naive Memory Access</a></li>
  <li><a href="#optimal-memory-access" id="toc-optimal-memory-access" class="nav-link" data-scroll-target="#optimal-memory-access">Optimal Memory Access</a></li>
  <li><a href="#a-middle-ground-tiling" id="toc-a-middle-ground-tiling" class="nav-link" data-scroll-target="#a-middle-ground-tiling">A Middle Ground: Tiling</a></li>
  </ul></li>
  <li><a href="#tiling-on-gpus-cuda" id="toc-tiling-on-gpus-cuda" class="nav-link" data-scroll-target="#tiling-on-gpus-cuda">Tiling on GPUs &amp; CUDA</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="tiled-matrix-multiplication.webp" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Tiled MatMul according to ChatGPT"><img src="tiled-matrix-multiplication.webp" class="img-fluid figure-img" style="width:100.0%" data-text-align="center" alt="Tiled Matrix Multiplication"></a></p>
<figcaption>Tiled MatMul according to ChatGPT</figcaption>
</figure>
</div>
<p><strong>TL;DR:</strong> Tiling is a technique used to reduce the number of memory accesses performed during matrix multiplication. We see how it improves compute intensity and how it speeds up the matrix multiplication operation, not only on CPUs, but also on GPUs. I also provide a simple implementation of tiling in CUDA C.</p>
<section id="matrix-multiplication-recap" class="level1">
<h1>Matrix Multiplication Recap</h1>
<p>Matrix multiplication, where <span class="math inline">\(AB = C\)</span>, computes each element of <span class="math inline">\(C\)</span> as:</p>
<p><span class="math display">\[C_{ij} = \sum_{k=1}^n A_{ik} B_{kj}\]</span></p>
<p>For simplicity, assume <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are square matrices of size <span class="math inline">\(n\)</span>. Below is basic pseudocode for the operation, which involves <span class="math inline">\(2n^3\)</span> floating-point operations (flops), because of the triple nested loop:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb1-2"><a href="#cb1-2"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb1-3"><a href="#cb1-3"></a>        <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb1-4"><a href="#cb1-4"></a>            C[i][j] <span class="op">+=</span> A[i][k] <span class="op">*</span> B[k][j]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The code is correct, but it is inefficient in terms of its memory access pattern. Let’s see why.</p>
</section>
<section id="compute-intensity" class="level1">
<h1>Compute Intensity</h1>
<p>Besides the count of flops, the performance of a matmul is also determined by the memory access pattern. The matmul has to fetch data from main memory into a fast cache, compute, and then return the result to main memory. This roundtrip is time-consuming, and the cores can become idle waiting for the data from main memory. If so, the <strong>memory bandwidth</strong> becomes the bottleneck of the algorithm.</p>
<p>Key Concept: <strong>Compute Intensity</strong>. The compute intensity ratio, defined as flops per memory transfer, indicates whether an algorithm is limited by memory bandwidth or compute power. This concept originates from the Roofline model <span class="citation" data-cites="williams2009roofline">(<a href="#ref-williams2009roofline" role="doc-biblioref">Williams, Waterman, and Patterson 2009</a>)</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>To boost performance, maximize compute intensity by reducing memory transfers per flop.</p>
</div>
</div>
</section>
<section id="memory-access-analysis" class="level1">
<h1>Memory Access Analysis</h1>
<section id="naive-memory-access" class="level2">
<h2 class="anchored" data-anchor-id="naive-memory-access">Naive Memory Access</h2>
<p>In the naive approach, computing <span class="math inline">\(C_{ij}\)</span> requires fetching <span class="math inline">\(n\)</span> elements from <span class="math inline">\(A\)</span> (a row) and <span class="math inline">\(n\)</span> elements from <span class="math inline">\(B\)</span> (a column). That makes <span class="math inline">\(2n\)</span> memory accesses. <span class="math inline">\(C_{ij}\)</span> is computed as the dot product of the row and the column, which requires <span class="math inline">\(2n\)</span> flops (1 mult and 1 add, <span class="math inline">\(n\)</span> times). Thus, the compute intensity is: <span class="math display">\[
\text{Compute Intensity} = \frac{\text{flops}}{\text{memory transfers}} = \frac{2n}{2n} = 1
\]</span></p>
<p>Can we do better? In this naive implementation, we are performing redundant memory transfers: For example, to compute <span class="math inline">\(C_{11}\)</span>, and <span class="math inline">\(C_{12}\)</span>, we fetch the first row of <span class="math inline">\(A\)</span> twice from main memory.</p>
</section>
<section id="optimal-memory-access" class="level2">
<h2 class="anchored" data-anchor-id="optimal-memory-access">Optimal Memory Access</h2>
<p>If our cache was (theoretically) large enough, we would transfer all elements of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> into the cache at once (<span class="math inline">\(2n^2\)</span> transfers) and perform the full matrix multiplication (<span class="math inline">\(2n^3\)</span> flops).</p>
<p><span class="math display">\[
\text{Compute Intensity} = \frac{\text{flops}}{\text{memory transfers}} = \frac{2n^3}{2n^2} = n
\]</span> The larger the matrices, the higher the compute intensity.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<p>Assuming a matrix size of <span class="math inline">\(n=10,000\)</span>, the naive approach does 1 flop per memory transfer, while the optimal approach does 10,000 flops per memory transfer. This is a 10,000x speedup!</p>
</div>
</div>
</section>
<section id="a-middle-ground-tiling" class="level2">
<h2 class="anchored" data-anchor-id="a-middle-ground-tiling">A Middle Ground: Tiling</h2>
<p>Since caching entire matrices is impractical, we divide matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> into smaller square blocks of size <span class="math inline">\(r\)</span>, called <strong>tiles</strong>, perform block-wise multiplications, and aggregate the results.</p>
<p>But how does block-wise matrix multiplication work? Let’s go through an example to gain some intuition. We break the matrices <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(C\)</span> into 4 blocks each (2x2). Each of these blocks has size <span class="math inline">\(n/2\)</span>.</p>
<p><span class="math display">\[
\begin{bmatrix}
A_{11} &amp; A_{12} \\
A_{21} &amp; A_{22}
\end{bmatrix}
\begin{bmatrix}
B_{11} &amp; B_{12} \\
B_{21} &amp; B_{22}
\end{bmatrix} =
\begin{bmatrix}
C_{11} &amp; C_{12} \\
C_{21} &amp; C_{22}
\end{bmatrix}
\]</span></p>
<p>To compute an submatrix <span class="math inline">\(C_{ij}\)</span>, we multiply the corresponding blocks of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> and sum the results. For example:</p>
<p><span class="math display">\[
C_{11} = A_{11}B_{11} + A_{12}B_{21}
\]</span></p>
<p>In pseudocode this translates to the code below.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>n_blocks <span class="op">=</span> n <span class="op">//</span> r</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_blocks):</span>
<span id="cb2-3"><a href="#cb2-3"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(n_blocks):</span>
<span id="cb2-4"><a href="#cb2-4"></a>        <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(n_blocks):</span>
<span id="cb2-5"><a href="#cb2-5"></a>            C[i][j] <span class="op">+=</span> A[i][k] <span class="op">@</span> B[k][j]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Note that the entry <code>C[i][j]</code> is now a block matrix rather than a scalar, and the <code>@</code> operator denotes matrix multiplication, rather than scalar multiplication. Line 5 of the code above is loading blocks of size <span class="math inline">\(r^2\)</span> from <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> into the cache, which takes <span class="math inline">\(2r^2\)</span> memory transfers. Then, it multiplies the two blocks, which requires <span class="math inline">\(2r^3\)</span> flops.</p>
<p><span class="math display">\[
\text{Compute Intensity} = \frac{\text{flops}}{\text{memory transfers}} = \frac{2r^3}{2r^2} = r
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<p>Assuming a block size of <span class="math inline">\(r=100\)</span>, the naive approach does 1 flop per memory transfer, while the tiling approach does 100 flops per memory transfer. This is a 100x speedup!</p>
</div>
</div>
<p>It should be clear that <span class="math inline">\(1 \leq r \leq n\)</span>. Setting <span class="math inline">\(r=1\)</span>, we recover the naive approach, while setting <span class="math inline">\(r=n\)</span> we recover the optimal approach. The table below compares the performance of the different methods. Note that for the tiled method, the flops and memory transfers are measured per block, rather than per matrix.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 12%">
<col style="width: 29%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Flops</th>
<th>Memory Transfers</th>
<th>Flops/Memory Transfer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Naive</td>
<td><span class="math inline">\(2n^3\)</span></td>
<td><span class="math inline">\(2n \cdot n^2\)</span></td>
<td><span class="math inline">\(\frac{2n^3}{2n \cdot n^2} = 1\)</span></td>
</tr>
<tr class="even">
<td>Tiling</td>
<td><span class="math inline">\(2r^3\)</span></td>
<td><span class="math inline">\(2r^2\)</span></td>
<td><span class="math inline">\(\frac{r^3}{r^2} = r\)</span></td>
</tr>
<tr class="odd">
<td>Optimal (Theoretical)</td>
<td><span class="math inline">\(2n^3\)</span></td>
<td><span class="math inline">\(2n^2\)</span></td>
<td><span class="math inline">\(\frac{n^3}{n^2} = n\)</span></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="tiling-on-gpus-cuda" class="level1">
<h1>Tiling on GPUs &amp; CUDA</h1>
<p>GPUs have a large number of cores, which can quickly process the data arriving from memory. Therefore, the memory bandwidth is likely to be a bottleneck in matrix multiplication on GPUs. To relieve the pressure on the memory bandwidth, it’s necessary to reduce the number of memory transfers by using the tiling technique.</p>
<p>How is this actually implemented on a GPU? The code block below shows a simplified tiled matrix multiplication in CUDA C. The key idea is that the cache is explicitly written and read using CUDA <strong>shared memory</strong>. The keyword <code>__shared__</code> defines an array used as cache. The variables <code>row</code> and <code>col</code> indicate what element of the matrix <span class="math inline">\(C_{ij}\)</span> the function computes. Line 13 is the loop over blocks. Lines 15-16 load the data from main memory into the cache. Lines 22-24 perform the dot product needed, and accumulate the result. Finally, line 31 writes the result to global memory. The function <code>__syncthreads()</code> is a CUDA synchronization primitive to avoid a race condition between threads.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource c number-lines code-with-copy"><code class="sourceCode c"><span id="cb3-1"><a href="#cb3-1"></a>__global__ <span class="dt">void</span> tiledMatMul<span class="op">(</span><span class="dt">float</span> <span class="op">*</span>A<span class="op">,</span> <span class="dt">float</span> <span class="op">*</span>B<span class="op">,</span> <span class="dt">float</span> <span class="op">*</span>C<span class="op">,</span> <span class="dt">int</span> n<span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>    <span class="co">// Define shared memory arrays (cache)</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>    __shared__ <span class="dt">float</span> A_block<span class="op">[</span>TILE_SIZE<span class="op">][</span>TILE_SIZE<span class="op">];</span></span>
<span id="cb3-4"><a href="#cb3-4"></a>    __shared__ <span class="dt">float</span> B_block<span class="op">[</span>TILE_SIZE<span class="op">][</span>TILE_SIZE<span class="op">];</span></span>
<span id="cb3-5"><a href="#cb3-5"></a>    </span>
<span id="cb3-6"><a href="#cb3-6"></a>    <span class="co">// CUDA thread variables</span></span>
<span id="cb3-7"><a href="#cb3-7"></a>    <span class="dt">int</span> row <span class="op">=</span> blockIdx<span class="op">.</span>y <span class="op">*</span> blockDim<span class="op">.</span>y <span class="op">+</span> threadIdx<span class="op">.</span>y<span class="op">;</span></span>
<span id="cb3-8"><a href="#cb3-8"></a>    <span class="dt">int</span> col <span class="op">=</span> blockIdx<span class="op">.</span>x <span class="op">*</span> blockDim<span class="op">.</span>x <span class="op">+</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb3-9"><a href="#cb3-9"></a>    </span>
<span id="cb3-10"><a href="#cb3-10"></a>    <span class="dt">float</span> C_ij <span class="op">=</span> <span class="fl">0.0</span><span class="bu">f</span><span class="op">;</span></span>
<span id="cb3-11"><a href="#cb3-11"></a>    </span>
<span id="cb3-12"><a href="#cb3-12"></a>    <span class="co">// Loop over the blocks</span></span>
<span id="cb3-13"><a href="#cb3-13"></a>    <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> t <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> t <span class="op">&lt;</span> n <span class="op">/</span> TILE_SIZE<span class="op">;</span> t<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb3-14"><a href="#cb3-14"></a>        <span class="co">// Transfer data from main memory into the cache</span></span>
<span id="cb3-15"><a href="#cb3-15"></a>        A_block<span class="op">[</span>threadIdx<span class="op">.</span>y<span class="op">][</span>threadIdx<span class="op">.</span>x<span class="op">]</span> <span class="op">=</span> A<span class="op">[</span>row <span class="op">*</span> n <span class="op">+</span> t <span class="op">*</span> TILE_SIZE <span class="op">+</span> threadIdx<span class="op">.</span>x<span class="op">];</span></span>
<span id="cb3-16"><a href="#cb3-16"></a>        B_block<span class="op">[</span>threadIdx<span class="op">.</span>y<span class="op">][</span>threadIdx<span class="op">.</span>x<span class="op">]</span> <span class="op">=</span> B<span class="op">[(</span>t <span class="op">*</span> TILE_SIZE <span class="op">+</span> threadIdx<span class="op">.</span>y<span class="op">)</span> <span class="op">*</span> n <span class="op">+</span> col<span class="op">];</span></span>
<span id="cb3-17"><a href="#cb3-17"></a>        </span>
<span id="cb3-18"><a href="#cb3-18"></a>        <span class="co">// Ensure data transfer is complete before proceeding</span></span>
<span id="cb3-19"><a href="#cb3-19"></a>        __syncthreads<span class="op">();</span></span>
<span id="cb3-20"><a href="#cb3-20"></a>        </span>
<span id="cb3-21"><a href="#cb3-21"></a>        <span class="co">// Matrix multiply both blocks</span></span>
<span id="cb3-22"><a href="#cb3-22"></a>        <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> k <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> k <span class="op">&lt;</span> TILE_SIZE<span class="op">;</span> k<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb3-23"><a href="#cb3-23"></a>            C_ij <span class="op">+=</span> A_block<span class="op">[</span>threadIdx<span class="op">.</span>y<span class="op">][</span>k<span class="op">]</span> <span class="op">*</span> B_block<span class="op">[</span>k<span class="op">][</span>threadIdx<span class="op">.</span>x<span class="op">];</span></span>
<span id="cb3-24"><a href="#cb3-24"></a>        <span class="op">}</span></span>
<span id="cb3-25"><a href="#cb3-25"></a>        </span>
<span id="cb3-26"><a href="#cb3-26"></a>        <span class="co">// Finish multiplying the blocks before overwriting the cache next iteration</span></span>
<span id="cb3-27"><a href="#cb3-27"></a>        __syncthreads<span class="op">();</span></span>
<span id="cb3-28"><a href="#cb3-28"></a>    <span class="op">}</span></span>
<span id="cb3-29"><a href="#cb3-29"></a>    </span>
<span id="cb3-30"><a href="#cb3-30"></a>    <span class="co">// Transfer the result back to global memory</span></span>
<span id="cb3-31"><a href="#cb3-31"></a>    C<span class="op">[</span>row <span class="op">*</span> n <span class="op">+</span> col<span class="op">]</span> <span class="op">=</span> C_ij<span class="op">;</span></span>
<span id="cb3-32"><a href="#cb3-32"></a><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The CUDA code is more complicated than the pseudocode, but it makes the cache usage explicit. To run the code look at <a href="https://github.com/tomasruizt/Code-Along/blob/main/cuda-pmpp/03_matrix_multiplication/main.cu">my example on Github</a>, which has Makefile for compilation and execution. If you want to see a more complete version, you can find it in the book by <span class="citation" data-cites="kirk2016programming">(<a href="#ref-kirk2016programming" role="doc-biblioref">Kirk and Wen-Mei 2016</a>)</span>. They describe other techniques to optimize algorithms on GPUs, like memory coalescing, minimizing control divergence, and thread coarsening.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Tiling is a practical optimization technique for improving matrix multiplication performance by minimizing memory transfers and maximizing compute intensity. We saw how the memory access pattern affects the performance of matrix multiplication, and how tiling is implemented concretely in CUDA C.</p>
<p><strong>Acknowledgement:</strong> The author is funded by the Bavarian Research Institute for Digital Transformation (bidt) and the Ludwig Maximilian University of Munich.</p>
</section>
<section id="references" class="level1">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-kirk2016programming" class="csl-entry" role="listitem">
Kirk, David B, and W Hwu Wen-Mei. 2016. <em>Programming Massively Parallel Processors: A Hands-on Approach</em>. Morgan kaufmann.
</div>
<div id="ref-williams2009roofline" class="csl-entry" role="listitem">
Williams, Samuel, Andrew Waterman, and David Patterson. 2009. <span>“Roofline: An Insightful Visual Performance Model for Multicore Architectures.”</span> <em>Communications of the ACM</em> 52 (4): 65–76.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{ruiz2024,
  author = {Ruiz, Tomas},
  title = {How {Does} {Tiling} {Speed} {Up} {Matrix} {Multiplications}
    on {GPUs?}},
  date = {2024-12-23},
  url = {https://tomasruizt.github.io/posts/tiling-for-matrix-mult/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-ruiz2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Ruiz, Tomas. 2024. <span>“How Does Tiling Speed Up Matrix
Multiplications on GPUs?”</span> December 23, 2024. <a href="https://tomasruizt.github.io/posts/tiling-for-matrix-mult/">https://tomasruizt.github.io/posts/tiling-for-matrix-mult/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/tomasruizt\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"openEffect":"zoom","closeEffect":"zoom","selector":".lightbox","descPosition":"bottom","loop":false});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>