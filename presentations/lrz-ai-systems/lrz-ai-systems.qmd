---
title: "LRZ AI Systems"
subtitle: "LLM Inference"
author: "Tomas Ruiz"
institute: "Computational Social Sciences - LMU"
self-contained: false
format: 
   revealjs:
      slide-number: true
---

# Goals

1. See LRZ AI Systems in Action
2. Maximize Performance of GPUs

# Part I
::: {.subtitle}
LRZ AI Systems
:::

## LRZ AI Systems
- Cluster with over 160 GPUs ^[https://doku.lrz.de/1-general-description-and-resources-10746641.html]
- Free to Use for LMU & TUM Researchers
- Run code interactively or as batch jobs

## LRZ AI Systems - Overview

<!-- https://drive.google.com/file/d/15mDl0dYuTx-j2GOqr1Oof9F6H0CvzWmG/view?usp=drive_link -->
![LRZ AI Systems Overview](imgs/lrz-ai-systems.drawio.png)

# Live Coding

## SLURM Commands

We are now in the **login node**.

SLURM info: `sinfo`

![](imgs/command-sinfo.png)

## SLURM Commands

Get Worker Node (Allocate): `salloc`

![](imgs/command-salloc.png)

## SLURM Commands

Enter Worker Node: `srun`

We are now in the **worker node**, and have a GPU.

![](imgs/command-srun.png)

## Enroot Containers

However, we don't have admin privileges, so we can't install packages. Therefore, we need NVIDIA `enroot` containers[^2].
We import a PyTorch docker image^[https://hub.docker.com/r/pytorch/pytorch/tags], and use it.

![](imgs/command-enroot-import.png)

[^2]: https://github.com/NVIDIA/enroot

## Enroot Containers

After `import` we have to `create` the container.

![](imgs/command-enroot-create.png)

## Enroot Containers

Go into the container: `enroot start`. Finally, we have a GPU, and `sudo`. 

![](imgs/command-enroot-start.png)

## Enroot Containers

Since we imported the PyTorch image, `torch` is installed and CUDA available.

![](imgs/python-torch-cuda-available.png)

# Part II
::: {.subtitle}
Maximize Performance of GPUs
:::

## LLM Training vs Inference
- **Training:** Updating model parameters (e.g. fine-tuning).
   - Needs at least 3x more memory than inference.
- **Inference:** Generating predictions, text, etc. Focus Today.

## LLM Inference

Typically, our GPUs don't have enough VRAM for large models.

- Our CSS GPU (RTX 3090) has 24GB VRAM
- Rule of Thumb: VRAM = 3 x Params in B
- E.g. Llama3 8B = 24GB VRAM

But fitting the model in VRAM is only the first step.

We also need high **throughput** to process ever larger datasets.

# Live Coding

## LLM Inference

We will compare two LLM runtimes. Code is online ^[https://github.com/tomasruizt/vllm-hf-comparison].

HuggingFace Transformers
```shell
pip install transformers
```
vLLM (High Throughput) ^[https://github.com/vllm-project/vllm]

```shell
pip install vllm
```

## Takeaways
- Use powerful GPUs on LRZ AI Systems
- Really push the GPUs! E.g. with vLLM
- Test with your own data! Every setup is different.

# Thank you!

## LLM Inference

What is the max GPU performance on paper?

![Roofline Model for Performance[^5]](imgs/roofline-model.png)

[^5]: https://en.wikipedia.org/wiki/Roofline_model